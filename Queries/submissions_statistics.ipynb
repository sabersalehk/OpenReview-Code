{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "educational-priest",
   "metadata": {},
   "source": [
    "# Compiles various statistics for submissions and reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca3efb5",
   "metadata": {},
   "source": [
    "* Get the reviews for all the papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e53705c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openreview\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "venue_id = 'auai.org/UAI/2024/Conference'\n",
    "\n",
    "cred_file = open('cred_info.txt', 'r')\n",
    "client = openreview.api.OpenReviewClient(\n",
    "    baseurl='https://api2.openreview.net',\n",
    "    username=cred_file.readline().strip(),\n",
    "    password=cred_file.readline().strip()\n",
    ")\n",
    "\n",
    "cred_file.close()\n",
    "\n",
    "venue_group = client.get_group(venue_id)\n",
    "under_review_id = venue_group.content['submission_venue_id']['value']\n",
    "submissions = client.get_all_notes(content={'venueid': under_review_id})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8173385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_submission_number(url):\n",
    "    # This regular expression looks for the word 'Submission' followed by one or more digits\n",
    "    match = re.search(r'Submission(\\d+)', url)\n",
    "    if match:\n",
    "        # The first group contains the digits after 'Submission'\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def extract_string_before_first_period_or_comma(text):\n",
    "    # Use regex to split the text at the first period or comma found\n",
    "    parts = re.split(r'[.,]', text, maxsplit=1)\n",
    "    if parts:\n",
    "        return parts[0].strip()  # Returns the part before the period or comma, stripping any extra whitespace\n",
    "    return None  # Return None if there's no period or comma in the text\n",
    "\n",
    "\n",
    "\n",
    "def extract_string_up_to_second_colon(text):\n",
    "    # Split the text at all colons\n",
    "    parts = text.split(':')\n",
    "    # Check if there are enough parts to have two colons\n",
    "    if len(parts) > 2:\n",
    "        # Rejoin the first two parts with a colon, adding back the second colon that was removed in splitting\n",
    "        return ':'.join(parts[:2]) \n",
    "    return None  # Return None if there aren't enough colons\n",
    "\n",
    "\n",
    "table = []\n",
    "cnt = 0 \n",
    "\n",
    "for submission in submissions:\n",
    "    print(cnt)\n",
    "    reviews = client.get_notes(forum=submission.forum)\n",
    "    AC_recomm = 'NA'\n",
    "    AC_conf = 'NA'\n",
    "    AC_indiff = 'NA'\n",
    "    num_comments = len(reviews)\n",
    "    submission_ID = 0\n",
    "    reviewers = []\n",
    "    for j in range(num_comments):\n",
    "        try:\n",
    "            Decision = reviews[j].content['decision']['value']\n",
    "        except:\n",
    "            do_nothing = 1\n",
    "        try:\n",
    "            AC_recomm = reviews[j].content['Recommendation']['value']\n",
    "            AC_conf = reviews[j].content['confidence']['value']\n",
    "            AC_indiff = reviews[j].content['Indifference']['value']\n",
    "        except:\n",
    "            do_nothing = 1\n",
    "        try:\n",
    "            if submission_ID == 0:\n",
    "                for k in range(len(reviews[j].readers)):\n",
    "                    temp = extract_submission_number(reviews[j].readers[k])\n",
    "                    if temp != None:\n",
    "                        submission_ID = temp\n",
    "        except:\n",
    "            do_nothing = 1\n",
    "        try:\n",
    "            reviewers.append((extract_string_up_to_second_colon(reviews[j].content['Q6_Overall_score']['value']), extract_string_before_first_period_or_comma(reviews[j].content['Q8_Confidence_in_your_score']['value'])))\n",
    "        except:\n",
    "            do_nothing = 1\n",
    "    cnt = cnt + 1 \n",
    "\n",
    "    row = {\n",
    "        \"Submission_ID\": submission_ID,\n",
    "        \"Decision\": Decision,\n",
    "        \"AC_Recommendation\": AC_recomm,\n",
    "        \"AC_Confidence\": AC_conf,\n",
    "        \"AC_Indifference\": AC_indiff,\n",
    "        \"Reviewers_Scores_Confidence\": reviewers,\n",
    "        \"Number_of_Comments\": num_comments,\n",
    "    }\n",
    "    \n",
    "    # Append the row dictionary to the table list\n",
    "    table.append(row)\n",
    "    \n",
    "df = pd.DataFrame(table)\n",
    "\n",
    "# Now you can easily export this to a CSV file\n",
    "df.to_csv(\"submissions_details.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "82c37701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# Function to parse the string representation of list of tuples\n",
    "# and calculate the average of first and second entry in tuples.\n",
    "def calculate_average_scores(confidence_string):\n",
    "    # Use 'ast.literal_eval' to safely evaluate the string as a Python literal\n",
    "    tuples = ast.literal_eval(confidence_string)\n",
    "    \n",
    "    # Initialize sums\n",
    "    sum_scores = 0\n",
    "    sum_confidence = 0\n",
    "    \n",
    "    # Loop through each tuple\n",
    "    for score_confidence in tuples:\n",
    "        # Extract and sum up the numeric part of the scores and confidence\n",
    "        sum_scores += int(score_confidence[0].split(':')[0])\n",
    "        sum_confidence += int(score_confidence[1].split(':')[0])\n",
    "    \n",
    "    # Calculate averages\n",
    "    average_score = round(sum_scores / len(tuples),1)\n",
    "    average_confidence = round(sum_confidence / len(tuples),1)\n",
    "    \n",
    "    # Return the averages as a tuple\n",
    "    return (average_score, average_confidence)\n",
    "\n",
    "# Function to add a new column with average score and confidence\n",
    "def add_average_score_confidence_column(file_path):\n",
    "    # Read the Excel file\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # Apply the 'calculate_average_scores' function to each entry in the 'Reviewers_Scores_Confidence' column\n",
    "    df['ave_score_confidence'] = df['Reviewers_Scores_Confidence'].apply(calculate_average_scores)\n",
    "    \n",
    "    # Split the tuple into two separate columns for better readability and use in Excel\n",
    "    df[['average_score', 'average_confidence']] = pd.DataFrame(df['ave_score_confidence'].tolist(), index=df.index)\n",
    "    df.drop('ave_score_confidence', axis=1, inplace=True)  # Drop the combined column if not needed\n",
    "    \n",
    "    # Save the updated DataFrame back to a new Excel file\n",
    "    df.to_excel('submissions_details_26_Apr.xlsx', index=False)\n",
    "\n",
    "# Replace 'your_file.xlsx' with the path to your actual Excel file\n",
    "add_average_score_confidence_column('submissions_details.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd3b530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "\n",
    "# Load the data from an Excel file\n",
    "df = pd.read_excel('submissions_details.xlsx', engine='openpyxl')\n",
    "\n",
    "# Add a new column that flags rows where 'Decision' and 'AC_recommendation' are different\n",
    "df['Different'] = df['Decision'] != df['AC_recommendation']\n",
    "\n",
    "# Save the DataFrame back to an Excel file, keeping the index to reference rows\n",
    "output_path = 'submissions_details.xlsx'\n",
    "df.to_excel(output_path, index=True, engine='openpyxl')\n",
    "\n",
    "# Load the workbook and the specific worksheet\n",
    "wb = load_workbook(output_path)\n",
    "ws = wb.active\n",
    "\n",
    "# Define the highlight style\n",
    "red_fill = PatternFill(start_color='FFFF00', end_color='FFFF00', fill_type='solid')\n",
    "\n",
    "# Apply formatting to rows where 'Different' is True\n",
    "for idx, row in enumerate(df['Different'], start=2):  # start=2 to account for the header row\n",
    "    if row:\n",
    "        for cell in ws[idx]:\n",
    "            cell.fill = red_fill\n",
    "\n",
    "# Save the changes to the Excel file\n",
    "wb.save(output_path)\n",
    "wb.close()\n",
    "\n",
    "print(\"Excel file has been updated and saved to\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afab172e",
   "metadata": {},
   "source": [
    "* Get the number of submitted reviews for each paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b8606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {'number of reviews':{}}\n",
    "for reviews_paper in all_reviews:\n",
    "    summary['number of reviews'].setdefault(str(reviews_paper[-1].number),len(reviews_paper) - 1)  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

